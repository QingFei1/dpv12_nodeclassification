{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理时间较久，非一次完成，故会存储几个中间处理文件以防处理结果丢失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [00:00, 941098.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of venue ids 396\n",
      "load dblp.v12.json...\n",
      "load done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4894081it [00:34, 143733.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数据数 4894080 没有venue_id 47108\n",
      "拥有venue_id的数据 1316213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#提取出有id的数据，即在aminer_name_cluster_edit的id在dpv12的ven_id中的\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "\n",
    "raw_id=[]\n",
    "ven_id=[]\n",
    "labels = [\"0\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"10\", \"11\"]\n",
    "label_to_class = {label: i for i, label in enumerate(labels)}\n",
    "with open(\"data/aminer_name_cluster_edit.txt\",'r')as fin1:   \n",
    "    for items in tqdm(fin1):\n",
    "        item=items.strip().split('\\t')\n",
    "        if item[-1] in label_to_class:\n",
    "            ven_id.append(item[0])\n",
    "print(\"number of venue ids\", len(ven_id))\n",
    "\n",
    "with open (\"data/dblp.v12.json\",'rb') as  fin:\n",
    "    print(\"load dblp.v12.json...\")\n",
    "    raw=json.load(fin) \n",
    "    print(\"load done\")\n",
    "    i=0\n",
    "    for index, d in tqdm(enumerate(raw)):\n",
    "        try :\n",
    "            if str(d.get('venue').get('id')) in ven_id:\n",
    "                raw_id.append(d)\n",
    "        except:\n",
    "            i+=1\n",
    "            pass\n",
    "\n",
    "print(\"总数据数\",index,\"没有venue_id\",i)\n",
    "print(\"拥有venue_id的数据\",len(raw_id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1316213it [01:28, 14881.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总的dpv12_venue_id.json带标签数据 1316213 处理完新的数据： 1098513 没有摘要的文章 217700\n"
     ]
    }
   ],
   "source": [
    "#提取出需要的信息，并过滤没有摘要的数据\n",
    "new_data=[]\n",
    "no_abs=0\n",
    "for index,data in tqdm(enumerate(raw_id)):\n",
    "    # if index==10000:\n",
    "    #     break\n",
    "    new_dic={}\n",
    "    new_dic['id']=data.get('id')\n",
    "    new_dic['title']=data.get('title')\n",
    "    #获取摘要,摘要被压缩了，还原成正常摘要\n",
    "    try:\n",
    "        abs_length=data.get('indexed_abstract').get('IndexLength')\n",
    "        abs_dic=data.get('indexed_abstract').get('InvertedIndex')\n",
    "        abstract=[None for _ in range(abs_length)]\n",
    "        for key,values in abs_dic.items():\n",
    "            for i in values:\n",
    "                abstract[i]=key\n",
    "        str_abs=''\n",
    "        for i in abstract:\n",
    "            str_abs+=i+' '\n",
    "        str_abs=str_abs.strip(' ')\n",
    "        new_dic['abstract']=str_abs\n",
    "    except:\n",
    "        no_abs+=1\n",
    "        \n",
    "        continue\n",
    "\n",
    "    #获取作者信息\n",
    "    new_dic['authors']=data.get('authors')\n",
    "    new_dic['references']=data.get('references')\n",
    "    new_dic['fos']=data.get('fos')\n",
    "    new_dic['year']=data.get('year')\n",
    "    new_dic['venue']=data.get('venue')\n",
    "    new_data.append(new_dic)\n",
    "print(\"总的dpv12_venue_id.json带标签数据\",len(raw_id),\"处理完新的数据：\",len(new_data),\"没有摘要的文章\",no_abs)\n",
    "with open (\"data/dpv12_venue_id_filter.json\",'w')as fout3:\n",
    "    json.dump(new_data,fout3,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402160\n"
     ]
    }
   ],
   "source": [
    "# 利用del_noref.py文件进行删除不存在的引用的数据，得到dpv12_venue_id_filter_delrefid.json\n",
    "# Run del_noref.py to delete papers with non-existent references, and get dpv12_venue_id_filter_delrefid.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992606/992606 [00:00<00:00, 1122225.72it/s]\n",
      "100%|██████████| 992606/992606 [00:00<00:00, 1172887.30it/s]\n",
      "100%|██████████| 992606/992606 [00:07<00:00, 130557.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import json\n",
    "#下面利用venue_id给数据打标签为0-8\n",
    "id_lab={}\n",
    "with open('data/aminer_name_cluster_edit.txt','r')as fi1:\n",
    "    for line in fi1:\n",
    "        items=line.strip().split('\\t')\n",
    "        id=int(items[0])\n",
    "        name=items[1]\n",
    "        label=items[2]\n",
    "        if label in label_to_class:\n",
    "            id_lab[id]=label_to_class[label]\n",
    "\n",
    "#之前数据中对应的标签有-1，cogdl处理得到的num_classe出错，在aminer_name_cluster_edit.txt直接替换改为18\n",
    "\n",
    "with open(\"data/dpv12_venue_id_filter_delrefid.json\",'r')as fp:\n",
    "    data=json.load(fp)\n",
    "    for index,da in enumerate(tqdm(data)):\n",
    "        lid=da['venue']['id']\n",
    "        da['label']=id_lab[lid]\n",
    "\n",
    "#使用顺序索引来作为edge_index,添加index,references_index\n",
    "id_index={}\n",
    "\n",
    "for index,da in enumerate(tqdm(data)):\n",
    "    id_index[da['id']]=index\n",
    "    da['index']=index\n",
    "    \n",
    "for index,da in enumerate(tqdm(data)):\n",
    "    ref=da['references']\n",
    "    ref_list=[]\n",
    "    if ref!=None:\n",
    "        for item in ref:\n",
    "            ref_index=id_index.get(item)\n",
    "            ref_list.append(ref_index)\n",
    "    da['references_index']=ref_list\n",
    "\n",
    "\n",
    "with open('data/dpv12_last.json','w')as fout_1:\n",
    "    data=json.dump(data,fout_1,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "with open('data/dpv12_last.json','r') as fi2:\n",
    "    data=json.load(fi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992606/992606 [00:01<00:00, 795944.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#下面来抽取出graph，即图的引用关系\n",
    "\n",
    "ref_list=[]\n",
    "\n",
    "for index,da in enumerate(tqdm(data)):\n",
    "    \n",
    "    res=da['references_index']\n",
    "    ref_dic={}\n",
    "    if len(res)!=0:\n",
    "        ref_dic['index']=da['index']\n",
    "        ref_dic['references_index']=res\n",
    "        ref_list.append(ref_dic)\n",
    "cita=[]\n",
    "with open('data/graph.txt','w')as fo2:\n",
    " \n",
    "    for i in ref_list:\n",
    "        id=str(i['index'])\n",
    "        for j in i['references_index']:\n",
    "            cita.append(str(j)+' '+id+'\\n')\n",
    "    fo2.writelines(cita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992606/992606 [00:00<00:00, 1112157.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train长度 634273 test 250555 valid 107778\n"
     ]
    }
   ],
   "source": [
    "#根据年份划分训练集，测试集\n",
    "\n",
    "train=[]\n",
    "valid=[]\n",
    "test=[]\n",
    "for index,da in enumerate(tqdm(data)):\n",
    "    year=da['year']\n",
    "    if year<= 2012:\n",
    "        train.append(da)\n",
    "    elif year<=2014:\n",
    "        valid.append(da)\n",
    "    else:\n",
    "        test.append(da)\n",
    "print(\"train长度\",len(train),\"test\",len(test),\"valid\",len(valid))\n",
    "with open('data/dpv12_train.json','w')as fs2:\n",
    "    json.dump(train,fs2,ensure_ascii=False)\n",
    "with open('data/dpv12_valid.json','w')as fs2:\n",
    "    json.dump(valid,fs2,ensure_ascii=False)\n",
    "with open('data/dpv12_test.json','w')as fs2:\n",
    "    json.dump(test,fs2,ensure_ascii=False)\n",
    "\n",
    "\n",
    "#提取出y，ty,vy\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "y_valid=[]\n",
    "\n",
    "for i in train:\n",
    "    y_train.append(str(i['label'])+'\\n')\n",
    "\n",
    "for i in valid:\n",
    "    y_valid.append(str(i['label'])+'\\n')\n",
    "\n",
    "for i in test:\n",
    "    y_test.append(str(i['label'])+'\\n')\n",
    "with open('data/y.txt','w') as fo1:\n",
    "    fo1.writelines(y_train)\n",
    "with open('data/ty.txt','w') as fo1:\n",
    "    fo1.writelines(y_test)\n",
    "with open('data/vy.txt','w') as fo1:\n",
    "    fo1.writelines(y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4b4b156aa8560666d964095090f6db92040aae170280822d9d71c646020d410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
